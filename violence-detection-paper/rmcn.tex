\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{caption}
% \usepackage{subcaption}
% \usepackage{subfig}
\usepackage{subfigure}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{float}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}
\bstctlcite{IEEEexample:BSTcontrol}

%%%%%%%%% TITLE
\title{Two-stream Multi-dimensional Convolutional Network for Real-time Violence Detection}

\author{\IEEEauthorblockN{Dipon Kumar Ghosh and Amitabha Chakrabarty}
\IEEEauthorblockA{\textit{Department of Computer Science and Engineering, BRAC University, Dhaka, Bangladesh}}
% \IEEEauthorblockA{\textit{$^2$Department of Computer Science and Engineering, Sejong University, Seoul, South Korea}}
}

\maketitle
\thispagestyle{plain}
\pagestyle{plain}
% \thispagestyle{empty}

% 	% 	%		%		%		% 	% 	%		%		%		%

%  Abstract   %

% 	% 	%		%		%		% 	% 	%		%		%		%

% TODO: add use only rgb frames

\begin{abstract}
The increasing number of surveillance cameras and security concerns have made automatic violent activity detection from surveillance footage an active area for research. 
Modern deep learning methods have achieved good accuracy in violence detection and proved to be successful because of their applicability in intelligent surveillance systems.
However, the models are computationally expensive and large in size because of their inefficient methods for feature extraction.
This work presents a novel architecture for violence detection called Two-stream Multi-dimensional Convolutional Network (2s-MDCN), which uses RGB frames and optical flow to detect violence. 
Our proposed method extracts temporal and spatial information independently by 1D, 2D, and 3D convolutions. 
% Moreover, addition of concatenated skip connections in MDCN proved to have increased performance. 
Despite combining multi-dimensional convolutional networks, our models are lightweight and efficient due to reduced channel capacity, yet they learn to extract meaningful spatial and temporal information.
Additionally, combining RGB frames and optical flow yields 2.2\% more accuracy than a single RGB stream.
Regardless of having less complexity, our models obtained state-of-the-art accuracy of 89.7$\%$ on the largest violence detection benchmark dataset. 

\end{abstract}


\begin{IEEEkeywords}
Real-time violence detection, convolutional neural network (CNN), spatio-temporal feature extraction, surveillance system
\end{IEEEkeywords}    
            

\input{1-intro}	
\input{2-related_work}	
\input{3-methodology}
\input{4-experiment} 
\input{5-result}    

      
      
    \section{Conclusion}
    In this work, we have represented a novel architecture for violence detection. 
    This model achieves state-of-the-art accuracy in the largest violence detection dataset. 
    This is possible by extracting efficient temporal and spatial features and reducing the loss of information during the prediction process.
    Our model outperformed FlowGate(fusion) with almost one-fourth of computational cost and better accuracy.
    As our model takes less memory, consumes less power, and removes pre-processing overhead, it becomes a suitable candidate for a violence detection model which can be deployed in real-life scenarios.
    
    
%\nocite{*}
    
{\small
\bibliographystyle{ieee}
\bibliography{rmcn}
}

\end{document}
